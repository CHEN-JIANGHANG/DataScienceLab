{
 "metadata": {
  "name": "",
  "signature": "sha256:170bdf6bc19704ec15e5301e44cd4b0c61f09117c62198be65af059712885282"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Random Forest<span/>\n",
      "<img src=\"../images/random_forest.png\" style=\"height:400px\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Contents\n",
      "- [Background](#background)\n",
      "- [Titanic Dataset](#titanic-dataset)\n",
      "    - [Preliminaries](#preliminaries)\n",
      "    - [Load Data](#load-data)\n",
      "    - [Build Dataframe](#build-dataframe)\n",
      "    - [Fit Model](#fit-model)\n",
      "    - [Parameter Estimation](#parameter-estimation)\n",
      "    - [Model Evaluation](#model-evaluation)\n",
      "        - [Confusion Matrix](#confusion-matrix)\n",
      "        - [Precision-Recall](#precision-recall)\n",
      "        - [Prediction Probability](#prediction-probability)\n",
      "        - [ROC](#roc)\n",
      "    - [Comparison between Classifiers](#comparison-between-classifiers)\n",
      "    - [Feature Selection](#feature-selection)\n",
      "- [References](#references)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Background\n",
      "[back to top](#contents)\n",
      "\n",
      "###<span style=\"background-color:#FF99FF)\">Basics of Decision Trees</span>\n",
      "* Can be applied to both regression and classification problems\n",
      "\n",
      "###1. Regression Trees\n",
      "- Log a variable so its distribution has more of a typical bell-shape\n",
      "- More interpretable\n",
      "- Process of building a regression tree:\n",
      "    - Divide the data into different non-overlapping regions\n",
      "    - Every observation that falls in a region, we make the same prediction (which is the mean of the response values for training observations in the region\n",
      "- How to divide into different regions?\n",
      "    - Can be any shape but we divide into rectangles and boxes for simplicity\n",
      "    - Goal is to find boxes which minimize the RSS\n",
      "    - Impossible to consider every partition, so we take top-down, greedy approach (recursive binary splitting)\n",
      "    - Top-down: Begins at the top and split into different branches\n",
      "    - Greedy: At each step, best split is made instead of looking ahead and pick 1 which might lead to better\n",
      "- Tree Pruning - build tree once the decrease in RSS due to each split exceeds a threshold\n",
      "- Good strategy would be to grow a very large tree, then prune it to obtain a subtree\n",
      "- What is the best way to prune a tree? Cost complexity pruning (weakest link pruning) -  index by nonnegative tuning parameter $\\alpha$\n",
      "\n",
      "**How to build a regression tree?**\n",
      "- Use recursive binary splitting to grow a large tree. Stop when each terminal node has less than a no. of observations\n",
      "- Apply cost complexity pruning - to get best subtrees as a function of $\\alpha$\n",
      "- Use K-fold CV to choose $\\alpha$ which minimize the average error\n",
      "- Return the subtree from step 2 which uses the chosen value of $\\alpha$\n",
      "     \n",
      "###2. Classification Trees\n",
      "* Predict observation response based on most commonly occuring class of training observations\n",
      "* Same process as regression trees\n",
      "* Cannot use RSS, we use:\n",
      "    1. Classification error rate: Fraction of training observations which do not belong to the most common class\n",
      "    * Gini index: measure of total variance across the K classes (takes on small value when proportion of wrongly classified is small)\n",
      "    * Cross-entropy: Similar to Gini Index, small when error is small\n",
      "* When building a classification tree, Gini or Cross-entropy used to evaluate the quality of particular split\n",
      "* A tree might lead to 2 yes, it just shows the certainty of a yes\n",
      "\n",
      "###3. Trees vs Linear Models\n",
      "* Which is better?\n",
      "    * If relationship between features and responses well-approximated by linear regression, use linear regression\n",
      "    * If highly non-linear and complex relationship, use decision trees\n",
      "    * Use CV to estimate the test error\n",
      "\n",
      "###4. Adv and Disadv of Trees\n",
      "- Easy to explain to people\n",
      "- Closer to mirror human decision-making \n",
      "- Can be displayed graphically, easily interpretable\n",
      "- Can handle qualitative predictors without creating dummy variables\n",
      "- HOWEVER, trees do not have same predictive accuracy (BUT! aggregating many decision trees, we can improve the performance!)\n",
      "\n",
      "###<span style=\"background-color:#FF99FF)\">Bagging, Random Forests, Boosting</span>\n",
      "* Used to construct more powerful prediction models\n",
      "1. Bagging\n",
      "    * Decision trees suffer from high variance\n",
      "    * Bootstrap Aggregating (Bagging) - procedure for reducing the variance\n",
      "    * Averaging a set of observations reduces variance\n",
      "    * Not practical if we do not have access to multiple training sets, therefore use bootstrap by taking repeated sames from 1 training set\n",
      "    * Construct B regression trees using B bootstrapped training sets, and average the predictions\n",
      "    * Applying to classification trees: Use majority vote (predict based on most commonly occuring class among B predictions)\n",
      "    * Straightforward way to estimate test error of a bagged model (without CV): Out-of-Bag Error Estimation\n",
      "    * Use variable importance measures to see which variable is most important (based on decrease in Gini index)\n",
      "* Random Forests\n",
      "    * Improvement over bagged trees by de-correlating the trees\n",
      "    * At each split, algorithm NOT allowed to consider a majority of the available predictors\n",
      "    * RF force each split to consider only a subset of the predictors (decorrelating)\n",
      "    * Main difference between RF and Bagging: Choice of predictor subset size M\n",
      "* Boosting\n",
      "    * Instead of fitting the data hard and potentially overfitting, boosting learns slowly\n",
      "    * Difference between boosting and random forests: in boosting, growth of a particular tree takes into account other trees which have been grown. Smaller trees can aid in interpretability\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Titanic Dataset\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titanic = pd.read_csv('../data/titanic.csv')\n",
      "titanic.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>survived</th>\n",
        "      <th>pclass</th>\n",
        "      <th>sex</th>\n",
        "      <th>age</th>\n",
        "      <th>sibsp</th>\n",
        "      <th>parch</th>\n",
        "      <th>fare</th>\n",
        "      <th>embarked</th>\n",
        "      <th>class</th>\n",
        "      <th>who</th>\n",
        "      <th>adult_male</th>\n",
        "      <th>deck</th>\n",
        "      <th>embark_town</th>\n",
        "      <th>alive</th>\n",
        "      <th>alone</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td> S</td>\n",
        "      <td> Third</td>\n",
        "      <td>   man</td>\n",
        "      <td>  True</td>\n",
        "      <td> NaN</td>\n",
        "      <td> Southampton</td>\n",
        "      <td>  no</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td> C</td>\n",
        "      <td> First</td>\n",
        "      <td> woman</td>\n",
        "      <td> False</td>\n",
        "      <td>   C</td>\n",
        "      <td>   Cherbourg</td>\n",
        "      <td> yes</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "   survived  pclass     sex  age  sibsp  parch     fare embarked  class  \\\n",
        "0         0       3    male   22      1      0   7.2500        S  Third   \n",
        "1         1       1  female   38      1      0  71.2833        C  First   \n",
        "\n",
        "     who adult_male deck  embark_town alive  alone  \n",
        "0    man       True  NaN  Southampton    no  False  \n",
        "1  woman      False    C    Cherbourg   yes  False  "
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Build Dataframe\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = titanic\n",
      "# df = df.fillna(df.dropna().median()) #cheating as we using test set to compute\n",
      "feature1 = 'fare'\n",
      "feature2 = 'pclass'\n",
      "feature3 = 'age'\n",
      "dummy1 = 'sex'\n",
      "dummy2 = 'embarked'\n",
      "target = 'survived'\n",
      "\n",
      "#Extract categorical features\n",
      "df_features = pd.concat([df[[feature1, feature2, feature3]],\n",
      "                pd.get_dummies(df[dummy1], prefix=dummy1),\n",
      "                pd.get_dummies(df[dummy2], prefix=dummy2)],\n",
      "                axis=1)\n",
      "\n",
      "df_features = df_features.drop('sex_male', 1) #remove redundant binary feature\n",
      "df_features = df_features.fillna(-1) #to indicate -1 is missing value\n",
      "\n",
      "# df_features.head()\n",
      "df_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "fare          891\n",
        "pclass        891\n",
        "age           891\n",
        "sex_female    891\n",
        "embarked_C    891\n",
        "embarked_Q    891\n",
        "embarked_S    891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Fit Model\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import Imputer\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "X = df_features.values\n",
      "y = df[target].values\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
      "\n",
      "imputer = Imputer(strategy='mean', missing_values=-1)\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, \n",
      "                                 learning_rate=0.1,\n",
      "                                 subsample=.8, \n",
      "                                 max_features=.5)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', gb),\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=5, \n",
      "                         n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (min): 79.33%\n",
        "CV Score (mean): 82.72%\n",
        "CV Score (max): 86.44%\n",
        "CPU times: user 73 ms, sys: 100 ms, total: 173 ms\n",
        "Wall time: 576 ms\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.kde import gaussian_kde\n",
      "_ = plt.hist(scores, range=(0, 1), bins=30, alpha=0.2)\n",
      "x = np.linspace(0, 1, 1000)\n",
      "smoothed = gaussian_kde(scores).evaluate(x)\n",
      "plt.plot(x, smoothed, label=\"Smoothed distribution\")\n",
      "top = np.max(smoothed)\n",
      "plt.vlines([np.mean(scores)], 0, top, color='r', label=\"Mean test score\")\n",
      "plt.vlines([np.median(scores)], 0, top, color='b', linestyles='dashed',\n",
      "           label=\"Median test score\")\n",
      "plt.legend(loc='best')\n",
      "_ = plt.title(\"Cross Validated test scores distribution\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF6CAYAAAA9Ct2LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqUdAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109f8c790>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Parameter Estimation\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gb.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "params = {'imp__strategy': ['mean', 'median'],\n",
      "          'clf__learning_rate': [0.05, 0.1, 0.5],\n",
      "          'clf__max_features': [0.5, 1],\n",
      "          'clf__max_depth': [3, 4, 5]\n",
      "          }\n",
      "\n",
      "gs = GridSearchCV(pipeline, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(X_train, y_train)\n",
      "print \"GS Best Score: %0.2f%%\" % (100 * gs.best_score_)\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sorted(gs.grid_scores_, \n",
      "#        key=lambda x: x.mean_validation_score, \n",
      "#        reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Model Evaluation\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Confusion Matrix\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "def plot_confusion(cm):\n",
      "    plt.imshow(cm, interpolation='nearest')\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.set_cmap('Blues')\n",
      "    plt.colorbar()\n",
      "    \n",
      "    target_names = ['not survived', 'survived'] #[0,1]\n",
      "\n",
      "    tick_marks = np.arange(len(target_names))\n",
      "    plt.xticks(tick_marks, target_names)\n",
      "    plt.yticks(tick_marks, target_names)\n",
      "    \n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    plt.tight_layout()\n",
      "\n",
      "y_pred = gs.predict(X_test)\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "cm_normalized = cm.astype(np.float64) / cm.sum(axis=1)\n",
      "\n",
      "plot_confusion(cm_normalized)\n",
      "print cm_normalized"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Precision-Recall\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(y_test, y_pred,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Prediction Probability\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_proba = gs.predict_proba(X_test)\n",
      "y_pred_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####ROC\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(y_test, y_pred_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specificity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(y_test, y_pred_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Comparison between Classifiers\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = 5\n",
      "n_jobs = 4\n",
      "scoring = 'accuracy'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', logreg)\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=n_jobs,\n",
      "                         scoring=scoring)\n",
      "\n",
      "print \"Logistic Regression CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', rf)\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=n_jobs,\n",
      "                         scoring=scoring)\n",
      "\n",
      "print \"Random Forest CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = GradientBoostingClassifier(n_estimators=100, \n",
      "                                        learning_rate=0.05,\n",
      "                                        max_features=.5,\n",
      "                                        max_depth= 5,\n",
      "                                        subsample=.8)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', gb),\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=n_jobs,\n",
      "                         scoring=scoring)\n",
      "\n",
      "print \"Gradient Boosted Trees CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Feature Selection\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.fit(X, y)\n",
      "rf.fit(X, y)\n",
      "gb.fit(X, y)\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, logreg.coef_.ravel(), color=\"#F08080\")\n",
      "_ = plt.xticks(x + 0.5, df_features.columns)\n",
      "plt.title('Logistic Regression: Coefficients')\n",
      "sns.despine()\n",
      "plt.figure()\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, rf.feature_importances_)\n",
      "_ = plt.xticks(x + 0.5, df_features.columns)\n",
      "plt.title('Random Forest: Feature Importance')\n",
      "sns.despine()\n",
      "plt.figure()\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, gb.feature_importances_)\n",
      "_ = plt.xticks(x + 0.5, df_features.columns, rotation=30)\n",
      "plt.title('Gradient Boosted Trees: Feature Importance')\n",
      "sns.despine()\n",
      "\n",
      "plt.tight_layout();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###References\n",
      "[back to top](#contents)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}