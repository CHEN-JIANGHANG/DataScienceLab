{
 "metadata": {
  "name": "",
  "signature": "sha256:1a8053204292602eabd77e8bfc9c9c2ff032b9d6e5f2027ba72c6018ad15a897"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Random Forest<span/>\n",
      "<img src=\"../images/random_forest.png\" style=\"height:400px\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Contents\n",
      "- [Background](#background)\n",
      "- [Titanic Dataset](#titanic-dataset)\n",
      "    - [Preliminaries](#preliminaries)\n",
      "    - [Load Data](#load-data)\n",
      "    - [Build Dataframe](#build-dataframe)\n",
      "    - [Train-Test-Split](#train-test-split)\n",
      "    - [Standardized Features](#standardized-features)\n",
      "    - [Choose Estimator](#choose-estimator)\n",
      "    - [Cross-validation Iterator](#cross-validation-iterator)\n",
      "    - [Tune Hyperparameters](#tune-hyperparameters)\n",
      "    - [Model Evaluation](#model-evaluation)\n",
      "        - [Learning Curve](#learning-curve)\n",
      "        - [Confusion Matrix](#confusion-matrix)\n",
      "        - [Precision-Recall](#precision-recall)\n",
      "        - [Prediction Probability](#prediction-probability)\n",
      "        - [ROC](#roc)\n",
      "    - [Final Evaluation - Test Set](#final-evaluation-test-set)\n",
      "    - [Train Final Model - Whole Dataset](#train-final-model-whole-dataset)\n",
      "    - [Models Comparison](#models-comparison)\n",
      "    - [Features Comparison](#features-comparison)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Background\n",
      "[back to top](#contents)\n",
      "\n",
      "###<span style=\"background-color:#FF99FF)\">Basics of Decision Trees</span>\n",
      "* Can be applied to both regression and classification problems\n",
      "\n",
      "###1. Regression Trees\n",
      "- Log a variable so its distribution has more of a typical bell-shape\n",
      "- More interpretable\n",
      "- Process of building a regression tree:\n",
      "    - Divide the data into different non-overlapping regions\n",
      "    - Every observation that falls in a region, we make the same prediction (which is the mean of the response values for training observations in the region\n",
      "- How to divide into different regions?\n",
      "    - Can be any shape but we divide into rectangles and boxes for simplicity\n",
      "    - Goal is to find boxes which minimize the RSS\n",
      "    - Impossible to consider every partition, so we take top-down, greedy approach (recursive binary splitting)\n",
      "    - Top-down: Begins at the top and split into different branches\n",
      "    - Greedy: At each step, best split is made instead of looking ahead and pick 1 which might lead to better\n",
      "- Tree Pruning - build tree once the decrease in RSS due to each split exceeds a threshold\n",
      "- Good strategy would be to grow a very large tree, then prune it to obtain a subtree\n",
      "- What is the best way to prune a tree? Cost complexity pruning (weakest link pruning) -  index by nonnegative tuning parameter $\\alpha$\n",
      "\n",
      "**How to build a regression tree?**\n",
      "- Use recursive binary splitting to grow a large tree. Stop when each terminal node has less than a no. of observations\n",
      "- Apply cost complexity pruning - to get best subtrees as a function of $\\alpha$\n",
      "- Use K-fold CV to choose $\\alpha$ which minimize the average error\n",
      "- Return the subtree from step 2 which uses the chosen value of $\\alpha$\n",
      "     \n",
      "###2. Classification Trees\n",
      "* Predict observation response based on most commonly occuring class of training observations\n",
      "* Same process as regression trees\n",
      "* Cannot use RSS, we use:\n",
      "    1. Classification error rate: Fraction of training observations which do not belong to the most common class\n",
      "    * Gini index: measure of total variance across the K classes (takes on small value when proportion of wrongly classified is small)\n",
      "    * Cross-entropy: Similar to Gini Index, small when error is small\n",
      "* When building a classification tree, Gini or Cross-entropy used to evaluate the quality of particular split\n",
      "* A tree might lead to 2 yes, it just shows the certainty of a yes\n",
      "\n",
      "###3. Trees vs Linear Models\n",
      "* Which is better?\n",
      "    * If relationship between features and responses well-approximated by linear regression, use linear regression\n",
      "    * If highly non-linear and complex relationship, use decision trees\n",
      "    * Use CV to estimate the test error\n",
      "\n",
      "###4. Adv and Disadv of Trees\n",
      "- Easy to explain to people\n",
      "- Closer to mirror human decision-making \n",
      "- Can be displayed graphically, easily interpretable\n",
      "- Can handle qualitative predictors without creating dummy variables\n",
      "- HOWEVER, trees do not have same predictive accuracy (BUT! aggregating many decision trees, we can improve the performance!)\n",
      "\n",
      "###<span style=\"background-color:#FF99FF)\">Bagging, Random Forests, Boosting</span>\n",
      "* Used to construct more powerful prediction models\n",
      "1. Bagging\n",
      "    * Decision trees suffer from high variance\n",
      "    * Bootstrap Aggregating (Bagging) - procedure for reducing the variance\n",
      "    * Averaging a set of observations reduces variance\n",
      "    * Not practical if we do not have access to multiple training sets, therefore use bootstrap by taking repeated sames from 1 training set\n",
      "    * Construct B regression trees using B bootstrapped training sets, and average the predictions\n",
      "    * Applying to classification trees: Use majority vote (predict based on most commonly occuring class among B predictions)\n",
      "    * Straightforward way to estimate test error of a bagged model (without CV): Out-of-Bag Error Estimation\n",
      "    * Use variable importance measures to see which variable is most important (based on decrease in Gini index)\n",
      "* Random Forests\n",
      "    * Improvement over bagged trees by de-correlating the trees\n",
      "    * At each split, algorithm NOT allowed to consider a majority of the available predictors\n",
      "    * RF force each split to consider only a subset of the predictors (decorrelating)\n",
      "    * Main difference between RF and Bagging: Choice of predictor subset size M\n",
      "* Boosting\n",
      "    * Instead of fitting the data hard and potentially overfitting, boosting learns slowly\n",
      "    * Difference between boosting and random forests: in boosting, growth of a particular tree takes into account other trees which have been grown. Smaller trees can aid in interpretability\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Titanic Dataset\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\", \"#D55E00\",\n",
      "          \"#CC79A7\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\"]\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titanic = pd.read_csv('../data/titanic.csv')\n",
      "titanic.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>survived</th>\n",
        "      <th>pclass</th>\n",
        "      <th>sex</th>\n",
        "      <th>age</th>\n",
        "      <th>sibsp</th>\n",
        "      <th>parch</th>\n",
        "      <th>fare</th>\n",
        "      <th>embarked</th>\n",
        "      <th>class</th>\n",
        "      <th>who</th>\n",
        "      <th>adult_male</th>\n",
        "      <th>deck</th>\n",
        "      <th>embark_town</th>\n",
        "      <th>alive</th>\n",
        "      <th>alone</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td> S</td>\n",
        "      <td> Third</td>\n",
        "      <td>   man</td>\n",
        "      <td>  True</td>\n",
        "      <td> NaN</td>\n",
        "      <td> Southampton</td>\n",
        "      <td>  no</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td> C</td>\n",
        "      <td> First</td>\n",
        "      <td> woman</td>\n",
        "      <td> False</td>\n",
        "      <td>   C</td>\n",
        "      <td>   Cherbourg</td>\n",
        "      <td> yes</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "   survived  pclass     sex  age  sibsp  parch     fare embarked  class  \\\n",
        "0         0       3    male   22      1      0   7.2500        S  Third   \n",
        "1         1       1  female   38      1      0  71.2833        C  First   \n",
        "\n",
        "     who adult_male deck  embark_town alive  alone  \n",
        "0    man       True  NaN  Southampton    no  False  \n",
        "1  woman      False    C    Cherbourg   yes  False  "
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Build Dataframe\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = titanic\n",
      "# df = df.fillna(df.dropna().median()) #cheating as we using test set to compute\n",
      "feature1 = 'fare'\n",
      "feature2 = 'pclass'\n",
      "feature3 = 'age'\n",
      "dummy1 = 'sex'\n",
      "dummy2 = 'embarked'\n",
      "target = 'survived'\n",
      "\n",
      "#Extract categorical features\n",
      "df_features = pd.concat([df[[feature1, feature2, feature3]],\n",
      "                pd.get_dummies(df[dummy1], prefix=dummy1),\n",
      "                pd.get_dummies(df[dummy2], prefix=dummy2)],\n",
      "                axis=1)\n",
      "\n",
      "df_features = df_features.drop('sex_male', 1) #remove redundant binary feature\n",
      "df_features = df_features.fillna(-1) #to indicate -1 is missing value\n",
      "\n",
      "# df_features.head()\n",
      "df_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "fare          891\n",
        "pclass        891\n",
        "age           891\n",
        "sex_female    891\n",
        "embarked_C    891\n",
        "embarked_Q    891\n",
        "embarked_S    891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df_features.values\n",
      "y = df[target].values\n",
      "n_samples, n_features = X.shape\n",
      "print(\"No. of samples = %d\" % n_samples)\n",
      "print(\"No. of features = %d\" % n_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Train-Test-Split\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calibration_plot(clf, xtest, ytest):\n",
      "    prob = clf.predict_proba(X_test)[:, 1]\n",
      "    outcome = ytest\n",
      "    data = pd.DataFrame(dict(prob=prob, outcome=outcome))\n",
      "\n",
      "    bins = np.linspace(0, 1, 20)\n",
      "    cuts = pd.cut(prob, bins)\n",
      "    binwidth = bins[1] - bins[0]\n",
      "    \n",
      "    cal = data.groupby(cuts).outcome.agg(['mean', 'count'])\n",
      "    cal['pmid'] = (bins[:-1] + bins[1:]) / 2\n",
      "    cal['sig'] = np.sqrt(cal.pmid * (1 - cal.pmid) / cal['count'])\n",
      "        \n",
      "    ax = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
      "    p = plt.errorbar(cal.pmid, cal['mean'], cal['sig'])\n",
      "    plt.plot(cal.pmid, cal.pmid, linestyle='--', lw=1, color='k')\n",
      "    plt.ylabel(\"Empirical P(Feature)\")\n",
      "    \n",
      "    ax = plt.subplot2grid((3, 1), (2, 0), sharex=ax)\n",
      "    \n",
      "    plt.bar(left=cal.pmid - binwidth / 2, height=cal['count'],\n",
      "            width=.95 * (bins[1] - bins[0]),\n",
      "            fc=p[0].get_color())\n",
      "    \n",
      "    plt.xlabel(\"Predicted P(Feature)\")\n",
      "    plt.ylabel(\"Number\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time \n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "clf = GradientBoostingClassifier().fit(X_train, y_train)\n",
      "calibration_plot(clf, X_test, y_test)\n",
      "\n",
      "training_accuracy = clf.score(X_train, y_train)\n",
      "test_accuracy = clf.score(X_test, y_test)\n",
      "print(\"Train data shape: %r, Train target shape: %r\" % (X_train.shape, y_train.shape))\n",
      "print(\"Test data shape: %r, Test target shape: %r\" % (X_test.shape, y_test.shape))\n",
      "print \"Training Score: %0.2f%%\" % (100 * training_accuracy)\n",
      "print \"Test Score: %0.2f%%\" % (100 * test_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Standardized Features\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "# scaler = StandardScaler()\n",
      "# X_train_scaled = scaler.fit_transform(X_train)\n",
      "# X_test_scaled = scaler.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###PCA Visualization\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import TruncatedSVD\n",
      "\n",
      "pca = TruncatedSVD(n_components=2)\n",
      "X_pca = pca.fit_transform(X_train)\n",
      "\n",
      "X_pca.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import cycle\n",
      "\n",
      "for i, c in zip(np.unique(y_train), cycle(colors)):\n",
      "    plt.scatter(X_pca[y_train == i, 0], \n",
      "                X_pca[y_train == i, 1],\n",
      "                c=c, label=i, alpha=0.5)\n",
      "    \n",
      "_ = plt.legend(loc='upper left')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Choose Estimator\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import Imputer\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "X = df_features.values\n",
      "y = df[target].values\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
      "\n",
      "imputer = Imputer(strategy='mean', missing_values=-1)\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, \n",
      "                                 learning_rate=0.1,\n",
      "                                 subsample=.8, \n",
      "                                 max_features=.5)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', gb),\n",
      "])\n",
      "\n",
      "clf = pipeline.fit(X_train, y_train)\n",
      "\n",
      "train_score = clf.score(X_train, y_train)\n",
      "test_score = clf.score(X_test, y_test)\n",
      "\n",
      "print \"Train Score: %0.2f%%\" % (100 * (train_score))\n",
      "print \"Test Score: %0.2f%%\" % (100 * (test_score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Cross-validation Iterator\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "n_subsamples = 500\n",
      "X_small_train, y_small_train = X_train[:n_subsamples], y_train[:n_subsamples]\n",
      "\n",
      "cv = ShuffleSplit(n_samples, \n",
      "                  n_iter=50,\n",
      "                  test_size=0.2,\n",
      "                  random_state=0)\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=2,\n",
      "                         scoring='accuracy')\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.kde import gaussian_kde\n",
      "_ = plt.hist(scores, range=(0, 1), bins=30, alpha=0.2)\n",
      "x = np.linspace(0, 1, 1000)\n",
      "smoothed = gaussian_kde(scores).evaluate(x)\n",
      "plt.plot(x, smoothed, label=\"Smoothed distribution\")\n",
      "top = np.max(smoothed)\n",
      "plt.vlines([np.mean(scores)], 0, top, color='r', label=\"Mean test score\")\n",
      "plt.vlines([np.median(scores)], 0, top, color='b', linestyles='dashed',\n",
      "           label=\"Median test score\")\n",
      "plt.legend(loc='best')\n",
      "_ = plt.title(\"Cross Validated test scores distribution\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Tune Hyperparameters\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gb.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "params = {'imp__strategy': ['mean', 'median'],\n",
      "          'clf__learning_rate': [0.05, 0.1, 0.5],\n",
      "          'clf__max_features': [0.5, 1],\n",
      "          'clf__max_depth': [3, 4, 5]\n",
      "          }\n",
      "\n",
      "gs = GridSearchCV(pipeline, params, cv=3, n_jobs=-1)\n",
      "gs.fit(X_small_train, y_small_train)\n",
      "\n",
      "print \"GS Best Score: %0.2f%%\" % (100 * gs.best_score_)\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sorted(gs.grid_scores_, \n",
      "#        key=lambda x: x.mean_validation_score, \n",
      "#        reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Model Evaluation\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Learning Curve\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def LearningCurve(model, title, X, y):\n",
      "    plt.figure()\n",
      "    plt.xlabel(\"Training examples\")\n",
      "    plt.ylabel(\"Score\")\n",
      "    train_sizes, train_scores, test_scores = learning_curve(model, X, y)\n",
      "    train_scores_mean = np.mean(train_scores, axis=1)\n",
      "    train_scores_std = np.std(train_scores, axis=1)\n",
      "    test_scores_mean = np.mean(test_scores, axis=1)\n",
      "    test_scores_std = np.std(test_scores, axis=1)\n",
      "    plt.grid()\n",
      "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, \n",
      "                     train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n",
      "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
      "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
      "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
      "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
      "    plt.title(title)\n",
      "    plt.legend(loc=\"best\")\n",
      "    return plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.learning_curve import learning_curve\n",
      "\n",
      "learning_rate = gs.best_params_['clf__learning_rate']\n",
      "max_features = gs.best_params_['clf__max_features']\n",
      "max_depth = gs.best_params_['clf__max_depth']\n",
      "\n",
      "estimator = GradientBoostingClassifier(n_estimators=100, \n",
      "                                       learning_rate=learning_rate,\n",
      "                                       max_features=max_features,\n",
      "                                       max_depth=max_depth,\n",
      "                                       subsample=.8)\n",
      "\n",
      "title = \"Learning Curves (GB, learning_rate=%.4f, max_features=%.4f, max_depth=%.4f)\" % (learning_rate, max_features, max_depth)\n",
      "\n",
      "LearningCurve(estimator, title, X_train, y_train);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Confusion Matrix\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "def plot_confusion(cm):\n",
      "    plt.imshow(cm, interpolation='nearest')\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.set_cmap('Blues')\n",
      "    plt.colorbar()\n",
      "    \n",
      "    target_names = ['not survived', 'survived'] #[0,1]\n",
      "\n",
      "    tick_marks = np.arange(len(target_names))\n",
      "    plt.xticks(tick_marks, target_names)\n",
      "    plt.yticks(tick_marks, target_names)\n",
      "    \n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    plt.tight_layout()\n",
      "\n",
      "y_pred = gs.predict(X_test)\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "cm_normalized = cm.astype(np.float64) / cm.sum(axis=1)\n",
      "\n",
      "plot_confusion(cm_normalized)\n",
      "print cm_normalized"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Precision-Recall\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(y_test, y_pred,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Prediction Probability\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_proba = gs.predict_proba(X_test)\n",
      "y_pred_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####ROC\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(y_test, y_pred_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specificity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(y_test, y_pred_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Final Evaluation - Test Set\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Final Score on Test set: %0.2f%%\" % (100 * gs.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Train Final Model - Whole Dataset\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "gs.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Models Comparison\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', logreg)\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=2,\n",
      "                         scoring='accuracy')\n",
      "\n",
      "print \"Logistic Regression CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', rf)\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=2,\n",
      "                         scoring='accuracy')\n",
      "\n",
      "print \"Random Forest CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Features Comparison\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.fit(X, y)\n",
      "rf.fit(X, y)\n",
      "gb.fit(X, y)\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, logreg.coef_.ravel(), color=\"#F08080\")\n",
      "_ = plt.xticks(x + 0.5, df_features.columns)\n",
      "plt.title('Logistic Regression: Coefficients')\n",
      "sns.despine()\n",
      "plt.figure()\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, rf.feature_importances_)\n",
      "_ = plt.xticks(x + 0.5, df_features.columns)\n",
      "plt.title('Random Forest: Feature Importance')\n",
      "sns.despine()\n",
      "plt.figure()\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, gb.feature_importances_)\n",
      "_ = plt.xticks(x + 0.5, df_features.columns, rotation=30)\n",
      "plt.title('Gradient Boosted Trees: Feature Importance')\n",
      "sns.despine()\n",
      "\n",
      "plt.tight_layout();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}