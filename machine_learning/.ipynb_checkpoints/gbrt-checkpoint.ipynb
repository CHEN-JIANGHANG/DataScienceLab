{
 "metadata": {
  "name": "",
  "signature": "sha256:7eaca2e262a036ac5eefd8d5d35b47ba9f534e67b7db45007ed3bc4487c57f81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Gradient Boosting Regression Trees<span/>\n",
      "<img src=\"../images/gbrt.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Contents\n",
      "- [Background](#background)\n",
      "- [Digits Dataset](#digits-dataset)\n",
      "    - [Preliminaries](#preliminaries)\n",
      "    - [Load Data](#load-data)\n",
      "    - [Train-Test-Split](#train-test-split)\n",
      "    - [Standardized Features](#standardized-features)\n",
      "    - [PCA evaluation](#pca-evaluation)\n",
      "    - [Choose Estimator](#choose-estimator)\n",
      "    - [Cross-validation Iterator](#cross-validation-iterator)\n",
      "    - [Tune Hyperparameters](#tune-hyperparameters)\n",
      "    - [Model Evaluation](#model-evaluation)\n",
      "        - [Learning Curve](#learning-curve)\n",
      "        - [Confusion Matrix](#confusion-matrix)\n",
      "        - [Precision-Recall](#precision-recall)\n",
      "    - [Final Evaluation - Test Set](#final-evaluation-test-set)\n",
      "    - [Train Final Model - Whole Dataset](#train-final-model-whole-dataset)\n",
      "    - [Comparison between Classifiers](#comparison-between-classifiers)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Background\n",
      "[back to top](#contents)\n",
      "\n",
      "###<span style=\"background-color:#FF99FF)\">Gradient Boosting Regression Trees</span>\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Movies Dataset\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\", \"#D55E00\",\n",
      "          \"#CC79A7\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\"]\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('../data/critics.csv')\n",
      "# df.head(2)\n",
      "df.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Vectorizer\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "feature = df.quote\n",
      "target = (df.fresh == 'fresh').values.astype(np.int)\n",
      "\n",
      "vectorizer = TfidfVectorizer(min_df=2)\n",
      "\n",
      "X = vectorizer.fit_transform(feature)\n",
      "y = target\n",
      "\n",
      "n_samples, n_features = X.shape\n",
      "print(\"No. of samples = %d\" % n_samples)\n",
      "print(\"No. of features = %d\" % n_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Train-Test-Split\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calibration_plot(clf, xtest, ytest):\n",
      "    prob = clf.predict_proba(X_test)[:, 1]\n",
      "    outcome = ytest\n",
      "    data = pd.DataFrame(dict(prob=prob, outcome=outcome))\n",
      "\n",
      "    bins = np.linspace(0, 1, 20)\n",
      "    cuts = pd.cut(prob, bins)\n",
      "    binwidth = bins[1] - bins[0]\n",
      "    \n",
      "    cal = data.groupby(cuts).outcome.agg(['mean', 'count'])\n",
      "    cal['pmid'] = (bins[:-1] + bins[1:]) / 2\n",
      "    cal['sig'] = np.sqrt(cal.pmid * (1 - cal.pmid) / cal['count'])\n",
      "        \n",
      "    ax = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
      "    p = plt.errorbar(cal.pmid, cal['mean'], cal['sig'])\n",
      "    plt.plot(cal.pmid, cal.pmid, linestyle='--', lw=1, color='k')\n",
      "    plt.ylabel(\"Empirical P(Feature)\")\n",
      "    \n",
      "    ax = plt.subplot2grid((3, 1), (2, 0), sharex=ax)\n",
      "    \n",
      "    plt.bar(left=cal.pmid - binwidth / 2, height=cal['count'],\n",
      "            width=.95 * (bins[1] - bins[0]),\n",
      "            fc=p[0].get_color())\n",
      "    \n",
      "    plt.xlabel(\"Predicted P(Feature)\")\n",
      "    plt.ylabel(\"Number\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "clf = MultinomialNB().fit(X_train, y_train)\n",
      "\n",
      "calibration_plot(clf, X_test, y_test)\n",
      "\n",
      "training_accuracy = clf.score(X_train, y_train)\n",
      "test_accuracy = clf.score(X_test, y_test)\n",
      "print(\"Train data shape: %r, Train target shape: %r\" % (X_train.shape, y_train.shape))\n",
      "print(\"Test data shape: %r, Test target shape: %r\" % (X_test.shape, y_test.shape))\n",
      "print \"Training Score: %0.2f%%\" % (100 * training_accuracy)\n",
      "print \"Test Score: %0.2f%%\" % (100 * test_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #First 10\n",
      "# print vectorizer.get_feature_names()[:10] \n",
      "# #In the middle\n",
      "# print vectorizer.get_feature_names()[n_features // 2:n_features // 2 + 10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###PCA Visualization\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Use TruncatedSVD to accept sparse matrix as input (PCA for numpy array)\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "\n",
      "pca = TruncatedSVD(n_components=2)\n",
      "X_pca = pca.fit_transform(X_train)\n",
      "\n",
      "X_pca.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import cycle\n",
      "\n",
      "for i, c in zip(np.unique(y_train), cycle(colors)):\n",
      "    plt.scatter(X_pca[y_train == i, 0], \n",
      "                X_pca[y_train == i, 1],\n",
      "                c=c, label=i, alpha=0.5)\n",
      "    \n",
      "_ = plt.legend(loc='upper left')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Choose Estimator\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %%time\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('vec', TfidfVectorizer()),\n",
      "    ('clf', MultinomialNB())\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Cross-validation Iterator\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(pipeline, \n",
      "                         feature, target, \n",
      "                         cv=3)\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.kde import gaussian_kde\n",
      "_ = plt.hist(scores, range=(0, 1), bins=30, alpha=0.2)\n",
      "x = np.linspace(0, 1, 1000)\n",
      "smoothed = gaussian_kde(scores).evaluate(x)\n",
      "plt.plot(x, smoothed, color=colors[3], label=\"Smoothed distribution\")\n",
      "top = np.max(smoothed)\n",
      "plt.vlines([np.mean(scores)], 0, top, color=colors[1], label=\"Mean test score\")\n",
      "plt.vlines([np.median(scores)], 0, top, color=colors[0], linestyles='dashed',\n",
      "           label=\"Median test score\")\n",
      "plt.legend(loc='best')\n",
      "_ = plt.title(\"Cross Validated Test scores distribution\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Tune Hyperparameters\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clf.get_params()\n",
      "# vectorizer.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "params = {\n",
      "    'vec__min_df': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
      "#     'vec__max_df': [0.8, 1.0],\n",
      "#     'vec__ngram_range': [(1, 1), (1, 2)],\n",
      "#     'vec__use_idf': [True, False],\n",
      "    'clf__alpha': np.logspace(-6, 0, 7)\n",
      "}\n",
      "\n",
      "n_subsamples = 500\n",
      "X_small_train, y_small_train = X_train[:n_subsamples], y_train[:n_subsamples]\n",
      "\n",
      "gs = GridSearchCV(pipeline, params, cv=3)\n",
      "_ = gs.fit(feature, target)\n",
      "\n",
      "print \"GS Best Score: %0.2f%%\" % (100 * gs.best_score_)\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sorted(gs.grid_scores_, \n",
      "#        key=lambda x: x.mean_validation_score, \n",
      "#        reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Model Evaluation\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Learning Curve\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def LearningCurve(model, title, X, y):\n",
      "    plt.figure()\n",
      "    plt.xlabel(\"Training examples\")\n",
      "    plt.ylabel(\"Score\")\n",
      "    train_sizes, train_scores, test_scores = learning_curve(model, X, y)\n",
      "    train_scores_mean = np.mean(train_scores, axis=1)\n",
      "    train_scores_std = np.std(train_scores, axis=1)\n",
      "    test_scores_mean = np.mean(test_scores, axis=1)\n",
      "    test_scores_std = np.std(test_scores, axis=1)\n",
      "    plt.grid()\n",
      "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, \n",
      "                     train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n",
      "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
      "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
      "    plt.plot(train_sizes, train_scores_mean, 'o-', color=colors[1],label=\"Training score\")\n",
      "    plt.plot(train_sizes, test_scores_mean, 'o-', color=colors[3],label=\"Cross-validation score\")\n",
      "    plt.title(title)\n",
      "    plt.legend(loc=\"best\")\n",
      "    return plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.learning_curve import learning_curve\n",
      "\n",
      "alpha = gs.best_params_['clf__alpha']\n",
      "estimator = MultinomialNB(alpha=alpha)\n",
      "\n",
      "title = \"Learning Curves (Multinomial NB, alpha=%.4f)\" % (alpha)\n",
      "\n",
      "LearningCurve(estimator, title, X_train, y_train);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Validation Curve\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.learning_curve import validation_curve\n",
      "\n",
      "alpha_range = np.logspace(-6, 0, 7)\n",
      "\n",
      "train_scores, validation_scores = validation_curve(MultinomialNB(),\n",
      "                                                   X_train,\n",
      "                                                   y_train,\n",
      "                                                   'alpha',\n",
      "                                                   alpha_range,\n",
      "                                                   cv=5,\n",
      "                                                   n_jobs=-1\n",
      "                                                   )\n",
      "\n",
      "plt.semilogx(alpha_range, train_scores.mean(axis=1), 'o-', color=colors[1], label='Training score')\n",
      "plt.semilogx(alpha_range, validation_scores.mean(axis=1), 'o-', color=colors[3], label='Cross-validation score')\n",
      "plt.legend(loc='best')\n",
      "plt.xlabel(\"Alpha Range\")\n",
      "_ = plt.title('Validation curves');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Final Model Fitting\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha = gs.best_params_['clf__alpha']\n",
      "min_df = gs.best_params_['vec__min_df']\n",
      "\n",
      "vectorizer = TfidfVectorizer(min_df=min_df)\n",
      "\n",
      "X = vectorizer.fit_transform(feature)\n",
      "y = target\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "clf = MultinomialNB(alpha=alpha).fit(X_train, y_train)\n",
      "\n",
      "calibration_plot(clf, X_test, y_test)\n",
      "\n",
      "training_accuracy = clf.score(X_train, y_train)\n",
      "test_accuracy = clf.score(X_test, y_test)\n",
      "\n",
      "print \"Training Score: %0.2f%%\" % (100 * training_accuracy)\n",
      "print \"Test Score: %0.2f%%\" % (100 * test_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Confusion Matrix\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "def plot_confusion(cm):\n",
      "    plt.imshow(cm, interpolation='nearest')\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.set_cmap('Blues')\n",
      "    plt.colorbar()\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    plt.tight_layout()\n",
      "\n",
      "predicted = clf.predict(X_test)\n",
      "cm = confusion_matrix(y_test, predicted)\n",
      "cm_normalized = cm.astype(np.float64) / cm.sum(axis=1)\n",
      "\n",
      "plot_confusion(cm_normalized)\n",
      "print cm_normalized"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Precision-Recall\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(y_test, predicted))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Final Evaluation - Test Set\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Final Score on Test set: %0.2f%%\" % (100 * clf.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Inspecting Model Performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = np.array(vectorizer.get_feature_names())\n",
      "\n",
      "x = np.eye(X_test.shape[1])\n",
      "probs = clf.predict_log_proba(x)[:, 0]\n",
      "sorted_list = np.argsort(probs)\n",
      "\n",
      "good_words = words[sorted_list [:10]]\n",
      "bad_words = words[sorted_list [-10:]]\n",
      "\n",
      "good_prob = probs[sorted_list [:10]]\n",
      "bad_prob = probs[sorted_list [-10:]]\n",
      "\n",
      "print \"Good words\\t     P(fresh | word)\"\n",
      "for w, p in zip(good_words, good_prob):\n",
      "    print \"%20s\" % w, \"%0.2f\" % (1 - np.exp(p))\n",
      "    \n",
      "print \"Bad words\\t     P(fresh | word)\"\n",
      "for w, p in zip(bad_words, bad_prob):\n",
      "    print \"%20s\" % w, \"%0.2f\" % (1 - np.exp(p))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review1 = 'This movie is unforgettable and superb'\n",
      "review2 = 'This movie has terrible cast, avoid at all cost. Disappointment.'\n",
      "\n",
      "print clf.predict_proba(vectorizer.transform([review1]))\n",
      "print clf.predict_proba(vectorizer.transform([review2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}