{
 "metadata": {
  "name": "",
  "signature": "sha256:b193b49a2995a69591f75e3da485e43c9c2ff956ed69b0273ac0532ba3390578"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Model Selection and Evaluation<span/>\n",
      "<img src=\"../images/model_selection.png\" style=\"height:400px\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Contents\n",
      "- [Background](#background)\n",
      "- [Titanic Dataset](#titanic-dataset)\n",
      "    - [Preliminaries](#preliminaries)\n",
      "    - [Load Data](#load-data)\n",
      "    - [Build Dataframe](#build-dataframe)\n",
      "    - [Fit Model](#fit-model)\n",
      "    - [Parameter Estimation](#parameter-estimation)\n",
      "    - [Model Evaluation](#model-evaluation)\n",
      "        - [Confusion Matrix](#confusion-matrix)\n",
      "        - [Precision-Recall](#precision-recall)\n",
      "        - [Prediction Probability](#prediction-probability)\n",
      "        - [ROC](#roc)\n",
      "    - [Comparison between Classifiers](#comparison-between-classifiers)\n",
      "    - [Feature Selection](#feature-selection)\n",
      "- [References](#references)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Background\n",
      "[back to top](#contents)\n",
      "\n",
      "###<span style=\"background-color:#FF99FF)\">Basics of Model Selection</span>\n",
      "\n",
      "\n",
      "Metrics (Precision/Recall, ROC curve, Marginal Precision, Score Distribution - all items vs true items, boostrap to show uncertainty on ROC and P/R, Brier decomposition\n",
      "\n",
      "Cross-validation\n",
      "\n",
      "Model Comparison\n",
      "\n",
      "Feature Comparison\n",
      "\n",
      "\n",
      "how to improve precision/recall of a logreg model?\n",
      "\n",
      "- check data is clean: \n",
      "    - remove any row / sample with a NaN features, \n",
      "    - center features and scale them to unit variances\n",
      "- perform a grid search for all the parameters on the model\n",
      "\n",
      "- try more complex, non linear models such as SVM with kernels or random forest models such as the ExtraTreesClassifier\n",
      "\n",
      "- grid search for the optimal parameters : very important but more costly: there are more of them with non linear models.\n",
      "\n",
      "These are ways of taking into account not just the classification results, but the results **relative to the true category**.\n",
      "\n",
      "$$ {\\rm accuracy} \\equiv \\frac{\\rm correct~labels}{\\rm total~samples} $$\n",
      "\n",
      "$$ {\\rm precision} \\equiv \\frac{\\rm true~positives}{\\rm true~positives + false~positives} $$\n",
      "\n",
      "$$ {\\rm recall} \\equiv \\frac{\\rm true~positives}{\\rm true~positives + false~negatives} $$\n",
      "\n",
      "$$ F_1 \\equiv 2 \\frac{\\rm precision \\cdot recall}{\\rm precision + recall} $$\n",
      "\n",
      "The **accuracy**, **precision**, **recall**, and **f1-score** all range from 0 to 1, with 1 being optimal.\n",
      "Here we've used the following definitions:\n",
      "\n",
      "- *True Positives* are those which are labeled ``1`` which are actually ``1``\n",
      "- *False Positives* are those which are labeled ``1`` which are actually ``0``\n",
      "- *True Negatives* are those which are labeled ``0`` which are actually ``0``\n",
      "- *False Negatives* are those which are labeled ``0`` which are actually ``1``\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Titanic Dataset\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titanic = pd.read_csv('../data/titanic.csv')\n",
      "titanic.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Build Dataframe\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = titanic\n",
      "# df = df.fillna(df.dropna().median()) #cheating as we using test set to compute\n",
      "feature1 = 'fare'\n",
      "feature2 = 'pclass'\n",
      "feature3 = 'age'\n",
      "dummy1 = 'sex'\n",
      "dummy2 = 'embarked'\n",
      "target = 'survived'\n",
      "\n",
      "#Extract categorical features\n",
      "df_features = pd.concat([df[[feature1, feature2, feature3]],\n",
      "                pd.get_dummies(df[dummy1], prefix=dummy1),\n",
      "                pd.get_dummies(df[dummy2], prefix=dummy2)],\n",
      "                axis=1)\n",
      "\n",
      "df_features = df_features.drop('sex_male', 1) #remove redundant binary feature\n",
      "df_features = df_features.fillna(-1) #to indicate -1 is missing value\n",
      "\n",
      "# df_features.head()\n",
      "df_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Fit Model\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import Imputer\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "X = df_features.values\n",
      "y = df[target].values\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
      "\n",
      "imputer = Imputer(strategy='mean', missing_values=-1)\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, \n",
      "                                 learning_rate=0.1,\n",
      "                                 subsample=.8, \n",
      "                                 max_features=.5)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', gb),\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=5, \n",
      "                         n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Parameter Estimation\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gb.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "params = {'imp__strategy': ['mean', 'median'],\n",
      "          'clf__learning_rate': [0.05, 0.1, 0.5],\n",
      "          'clf__max_features': [0.5, 1],\n",
      "          'clf__max_depth': [3, 4, 5]\n",
      "          }\n",
      "\n",
      "gs = GridSearchCV(pipeline, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(X_train, y_train)\n",
      "print \"GS Best Score: %0.2f%%\" % (100 * gs.best_score_)\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sorted(gs.grid_scores_, \n",
      "#        key=lambda x: x.mean_validation_score, \n",
      "#        reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Model Evaluation\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Confusion Matrix\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "def plot_confusion(cm):\n",
      "    plt.imshow(cm, interpolation='nearest')\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.set_cmap('Blues')\n",
      "    plt.colorbar()\n",
      "    \n",
      "    target_names = ['not survived', 'survived'] #[0,1]\n",
      "\n",
      "    tick_marks = np.arange(len(target_names))\n",
      "    plt.xticks(tick_marks, target_names)\n",
      "    plt.yticks(tick_marks, target_names)\n",
      "    \n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    plt.tight_layout()\n",
      "\n",
      "y_pred = gs.predict(X_test)\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "cm_normalized = cm.astype(np.float64) / cm.sum(axis=1)\n",
      "\n",
      "plot_confusion(cm_normalized)\n",
      "print cm_normalized"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Precision-Recall\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(y_test, y_pred,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Prediction Probability\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred_proba = gs.predict_proba(X_test)\n",
      "y_pred_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####ROC\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(y_test, y_pred_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specificity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(y_test, y_pred_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Comparison between Classifiers\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = 5\n",
      "n_jobs = 4\n",
      "scoring = 'accuracy'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', logreg)\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=n_jobs,\n",
      "                         scoring=scoring)\n",
      "\n",
      "print \"Logistic Regression CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', rf)\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=n_jobs,\n",
      "                         scoring=scoring)\n",
      "\n",
      "print \"Random Forest CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = GradientBoostingClassifier(n_estimators=100, \n",
      "                                        learning_rate=0.05,\n",
      "                                        max_features=.5,\n",
      "                                        max_depth= 5,\n",
      "                                        subsample=.8)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', gb),\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, X, y, \n",
      "                         cv=cv, \n",
      "                         n_jobs=n_jobs,\n",
      "                         scoring=scoring)\n",
      "\n",
      "print \"Gradient Boosted Trees CV scores:\"\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Feature Selection\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.fit(X, y)\n",
      "rf.fit(X, y)\n",
      "gb.fit(X, y)\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, logreg.coef_.ravel(), color=\"#F08080\")\n",
      "_ = plt.xticks(x + 0.5, df_features.columns)\n",
      "plt.title('Logistic Regression: Coefficients')\n",
      "sns.despine()\n",
      "plt.figure()\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, rf.feature_importances_)\n",
      "_ = plt.xticks(x + 0.5, df_features.columns)\n",
      "plt.title('Random Forest: Feature Importance')\n",
      "sns.despine()\n",
      "plt.figure()\n",
      "\n",
      "x = np.arange(len(df_features.columns))\n",
      "plt.bar(x, gb.feature_importances_)\n",
      "_ = plt.xticks(x + 0.5, df_features.columns, rotation=30)\n",
      "plt.title('Gradient Boosted Trees: Feature Importance')\n",
      "sns.despine()\n",
      "\n",
      "plt.tight_layout();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###References\n",
      "[back to top](#contents)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}